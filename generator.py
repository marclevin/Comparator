import ast
import logging
import os
from typing import Tuple

import click
from dotenv import load_dotenv
from openai import OpenAI

from comparison.path_construction.comparator import distance
from comparison.structures.State import CodeState, IntermediateState


def generate_ai_hint(problem_description: str, student_code: str, edit: str, goal_code: str) -> Tuple[str, str]:
    load_dotenv()
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    if client is None:
        raise Exception("OpenAI client not initialized.")

    filled_template = populate_teacher_template(problem_description, student_code, edit)

    teacher_interaction = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "user", "content": f"{filled_template}"},
        ],
    )
    hints = extract_hints(teacher_interaction.choices[0].message.content)
    if hints is None:
        raise click.ClickException("No hints were generated by the AI.")
    long_form_hint, short_form_hint = hints
    # Log the hints
    logging.log(logging.INFO, f"Long-form hint: {long_form_hint}")
    logging.log(logging.INFO, f"Short-form hint: {short_form_hint}")

    filled_student_template = populate_student_template(long_form_hint, student_code)
    completions = []
    for _ in range(10):
        completion_student = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "user", "content": f"{filled_student_template}"},
            ],
        )
        completions.append(completion_student.choices[0].message.content)
    logging.log(logging.INFO, f"Student completions: {completions}")
    # Now to compare the completions to the goal code.
    student_code_state = CodeState(tree=ast.parse(student_code), goal=IntermediateState(tree=ast.parse(goal_code)))
    distances = [(distance(student_code_state, IntermediateState(tree=ast.parse(candidate_code))), candidate_code) for
                 candidate_code in completions]
    print(distances)
    # Returning the teacher response for now, since the student response is not implemented.
    # return completion_student.choices[0].message.content

    return short_form_hint, long_form_hint


def populate_teacher_template(problem_description, student_code, edit):
    teacher_template = ""
    try:
        with open("prompt/teacher.txt", "r") as f:
            teacher_template = f.read()
    except FileNotFoundError:
        raise Exception("Teacher template not found.")
    filled_template = teacher_template.format(
        problem_description=problem_description,
        student_code=student_code,
        edit=edit,
    )
    return filled_template


def populate_student_template(long_form_hint, student_code):
    student_template = ""
    try:
        with open("prompt/student.txt", "r") as f:
            student_template = f.read()
    except FileNotFoundError:
        raise Exception("Student template not found.")
    filled_student_template = student_template.format(
        student_code=student_code,
        long_form_hint=long_form_hint,
    )
    return filled_student_template


def extract_hints(response: str) -> Tuple[str, str]:
    # Find the start of the long-form hint
    start_index = response.find("Long-form hint:") + len("Long-form hint:")

    # Find the start of the short-form hint (which marks the end of the long-form hint)
    end_index = response.find("Short-form hint:")

    # Extract and strip any leading/trailing whitespace
    long_form_hint = response[start_index:end_index].strip()

    start_index = response.find("Short-form hint:") + len("Short-form hint:")
    short_form_hint = response[start_index:].strip()
    return long_form_hint, short_form_hint
